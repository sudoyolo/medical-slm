{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "In this notebook, we showcase how to fine-tune the Qwen3-1.7B model on AWS Trainium using the Hugging Face Optimum Neuron library.\n",
    "The goal of this task is Text-to-SQL generation â€” training the model to translate natural language questions into executable SQL queries.\n",
    "\n",
    "We will fine-tune the model using `optimum.neuron`, save the trained checkpoint, and then deploy it for inference with Optimum-Neuron[vllm], enabling high-performance, low-latency Text-to-SQL execution.\n",
    "\n",
    "By the end of this notebook, youâ€™ll have a fine-tuned, Trainium-optimized Qwen3 model ready for deployment and real-time inference. This workflow demonstrates how to leverage the Optimum Neuron toolchain to efficiently train and serve large language models on AWS Neuron devices.\n",
    "\n",
    "For this module, you will be using the [b-mc2/sql-create-context](https://huggingface.co/datasets/b-mc2/sql-create-context) dataset which consists of thousands of examples of SQL schemas, questions about the schemas, and SQL queries intended to answer the questions.\n",
    "\n",
    "*Dataset example 1:*\n",
    "* *SQL schema/context:* `CREATE TABLE management (department_id VARCHAR); CREATE TABLE department (department_id VARCHAR)`\n",
    "* *Question:* `How many departments are led by heads who are not mentioned?`\n",
    "* *SQL query/answer:* `SELECT COUNT(*) FROM department WHERE NOT department_id IN (SELECT department_id FROM management)`\n",
    "\n",
    "*Dataset example 2:*\n",
    "* *SQL schema/context:* `CREATE TABLE courses (course_name VARCHAR, course_id VARCHAR); CREATE TABLE student_course_registrations (student_id VARCHAR, course_id VARCHAR)`\n",
    "* *Question:* `What are the ids of all students for courses and what are the names of those courses?`\n",
    "* *SQL query/answer:* `SELECT T1.student_id, T2.course_name FROM student_course_registrations AS T1 JOIN courses AS T2 ON T1.course_id = T2.course_id`\n",
    "\n",
    "By fine-tuning the model over several thousand of these text-to-SQL examples, the model will then learn how to generate an appropriate SQL query when presented with a SQL context and a free-form question.\n",
    "\n",
    "This text-to-SQL use case was selected so you can successfully fine-tune your model in a reasonably short amount of time (~25 minutes) which is appropriate for this workshop. Although this is a relatively simple use case, please keep in mind that the same techniques and components used in this module can also be applied to fine-tune LLMs for more advanced use cases such as writing code, summarizing documents, creating blog posts - the possibilities are endless!\n",
    "\n",
    "# Install requirements\n",
    "This notebook uses [Hugging Face Optimum Neuron](https://github.com/huggingface/optimum-neuron) which works like an interface between the Hugging Face Transformers library and AWS Accelerators including AWS Trainium and AWS Inferentia. We will also install some other libraries like peft, trl etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environment/FineTuning/HuggingFaceExample/01_finetuning/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: optimum-neuron==0.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: peft==0.16.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: trl==0.11.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.11.4)\n",
      "Requirement already satisfied: huggingface_hub==0.33.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.33.4)\n",
      "Requirement already satisfied: datasets==3.6.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: transformers~=4.51.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (4.51.3)\n",
      "Requirement already satisfied: accelerate==1.8.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: optimum~=1.24.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (1.24.0)\n",
      "Requirement already satisfied: numpy<=1.25.2,>=1.22.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (1.25.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: psutil in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (2.7.1)\n",
      "Requirement already satisfied: tqdm in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: safetensors in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from trl==0.11.4->-r requirements.txt (line 3)) (0.9.35)\n",
      "Requirement already satisfied: filelock in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2025.3.0)\n",
      "Requirement already satisfied: requests in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (3.12.15)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from transformers~=4.51.0->optimum-neuron==0.3.0->-r requirements.txt (line 1)) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from transformers~=4.51.0->optimum-neuron==0.3.0->-r requirements.txt (line 1)) (0.21.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests->huggingface_hub==0.33.4->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests->huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests->huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2025.7.14)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (14.1.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (4.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0->-r requirements.txt (line 5)) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/environment/FineTuning/HuggingFaceExample/01_finetuning/assets\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "\n",
    "In this section, we fine-tune the Qwen3-1.7B model on the Text-to-SQL task using Hugging Face Optimum Neuron. Here are the parameters we are going to pass - \n",
    "\n",
    "1. `--nnodes`:\tNumber of nodes (1 = single node)\n",
    "2. `--nproc_per_node`: \tProcesses per node (usually equals number of devices).\n",
    "3. `--model_id, --tokenizer_id`:\tModel and tokenizer identifiers (from Hugging Face or local path).\n",
    "4. `--output_dir`:\tDirectory for saving checkpoints and logs.\n",
    "5. `--bf16`:\tEnables bfloat16 precision for faster, memory-efficient training.\n",
    "5. `--gradient_checkpointing`:\tSaves memory by recomputing activations during backprop.\n",
    "6. `--gradient_accumulation_steps`:\tSteps to accumulate gradients before optimizer update.\n",
    "7. `--learning_rate`:\tInitial training learning rate.\n",
    "8. `--max_steps`:\tTotal number of training steps.\n",
    "9. `--per_device_train_batch_size`:\tBatch size per device.\n",
    "10. `--tensor_parallel_size`:\tNumber of devices for tensor parallelism.\n",
    "11. `--lora_r, --lora_alpha, --lora_dropout`:\tLoRA hyperparameters â€” rank, scaling, and dropout rate.\n",
    "12. `--dataloader_drop_last`:\tDrops last incomplete batch.\n",
    "13. `--disable_tqdm`: Disables progress bar.\n",
    "14. `--logging_steps`:\tLog interval (in steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "neuronx_distributed imported OK\n",
      "['initialize_parallel_model', 'initialize_parallel_optimizer', 'parallel_layers']\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import neuronx_distributed as nxd; print('neuronx_distributed imported OK'); print([a for a in dir(nxd) if 'initialize' in a or 'parallel' in a][:20])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1108 22:28:27.825000 3332 torch/distributed/run.py:766] \n",
      "W1108 22:28:27.825000 3332 torch/distributed/run.py:766] *****************************************\n",
      "W1108 22:28:27.825000 3332 torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1108 22:28:27.825000 3332 torch/distributed/run.py:766] *****************************************\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "2025-11-08 22:28:38.524695: W neuron/nrt_adaptor.cc:53] nrt_tensor_write_hugepage() is not available, will fall back to nrt_tensor_write().\n",
      "2025-11-08 22:28:38.524729: W neuron/nrt_adaptor.cc:62] nrt_tensor_read_hugepage() is not available, will fall back to nrt_tensor_read().\n",
      "2025-11-08 22:28:38.525221: W neuron/nrt_adaptor.cc:53] nrt_tensor_write_hugepage() is not available, will fall back to nrt_tensor_write().\n",
      "2025-11-08 22:28:38.525253: W neuron/nrt_adaptor.cc:62] nrt_tensor_read_hugepage() is not available, will fall back to nrt_tensor_read().\n",
      "2025-Nov-08 22:28:38.0526 3341:3390 [0] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):213 CCOM WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "2025-Nov-08 22:28:38.0527 3342:3389 [1] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):213 CCOM WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "2025-Nov-08 22:28:38.0528 3341:3390 [0] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):354 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2025-Nov-08 22:28:38.0530 3342:3389 [1] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):354 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2025-Nov-08 22:28:38.0532 3341:3390 [0] ncclResult_t nccl_net_ofi_init_no_atexit_fini_v6(ncclDebugLogger_t):183 CCOM WARN NET/OFI Initializing plugin failed\n",
      "2025-Nov-08 22:28:38.0534 3342:3389 [1] ncclResult_t nccl_net_ofi_init_no_atexit_fini_v6(ncclDebugLogger_t):183 CCOM WARN NET/OFI Initializing plugin failed\n",
      "2025-Nov-08 22:28:38.0536 3341:3390 [0] net_plugin.cc:97 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
      "2025-Nov-08 22:28:38.0538 3342:3389 [1] net_plugin.cc:97 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
      "[2025-11-08 22:28:38.605: I neuronx_distributed/parallel_layers/parallel_state.py:628] > initializing tensor model parallel with size 2\n",
      "[2025-11-08 22:28:38.606: I neuronx_distributed/parallel_layers/parallel_state.py:629] > initializing pipeline model parallel with size 1\n",
      "[2025-11-08 22:28:38.606: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing context model parallel with size 1\n",
      "[2025-11-08 22:28:38.606: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing data parallel with size 1\n",
      "[2025-11-08 22:28:38.606: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing world size to 2\n",
      "2025-11-08 22:28:38.000615:  3341  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_910320559639473753+e30acd3a/model.neff\n",
      "2025-11-08 22:28:38.000616:  3342  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_910320559639473753+e30acd3a/model.neff\n",
      "[2025-11-08 22:28:38.643: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x742cfdb99480>, 'Ascending Ring PG Group')>\n",
      "[2025-11-08 22:28:38.644: I neuronx_distributed/parallel_layers/parallel_state.py:668] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1]]\n",
      "[2025-11-08 22:28:38.644: I neuronx_distributed/parallel_layers/parallel_state.py:669] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1]]\n",
      "[2025-11-08 22:28:38.644: I neuronx_distributed/parallel_layers/parallel_state.py:670] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1]]\n",
      "[2025-11-08 22:28:38.644: I neuronx_distributed/parallel_layers/parallel_state.py:671] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1]]\n",
      "[2025-11-08 22:28:38.644: I neuronx_distributed/parallel_layers/parallel_state.py:672] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1]]\n",
      "[2025-11-08 22:28:38.644: I neuronx_distributed/parallel_layers/parallel_state.py:673] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1]]\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "No Hugging Face token found in environment, checking AWS Secrets Manager...\n",
      "No Hugging Face token found in environment, checking AWS Secrets Manager...\n",
      "Logging in to Hugging Face Hub...\n",
      "Logging in to Hugging Face Hub...\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:00<00:00, 12375.43 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [00:00<00:00, 13917.63 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:00<00:00, 14961.45 examples/s]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/kvcache/kv_cache_manager.py:24: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..attention.gqa import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/kvcache/kv_cache_manager.py:24: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..attention.gqa import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:45: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:45: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:26<00:00, 13.19s/it]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:25<00:00, 12.79s/it]\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/transformers/training_args.py:2058: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/transformers/training_args.py:2058: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "Generating train split: 790 examples [00:00, 814.87 examples/s] \n",
      "Generating train split: 86 examples [00:00, 845.77 examples/s]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/trainers.py:1467: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `NeuronSFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer.__init__(self, *args, **kwargs)\n",
      "No label_names provided for model class `NeuronPeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/trainers.py:1726: UserWarning: You passed `packing=True` to the SFTTrainer/SFTConfig, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/trainers.py:1467: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `NeuronSFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer.__init__(self, *args, **kwargs)\n",
      "No label_names provided for model class `NeuronPeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/trainers.py:1726: UserWarning: You passed `packing=True` to the SFTTrainer/SFTConfig, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 790\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Total optimization steps = 1,000\n",
      "  Number of trainable parameters = 16,515,072\n",
      "model.neff: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.3k/11.3k [00:00<00:00, 79.0MB/s]\n",
      "2025-11-08 22:29:20.000861:  3341  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_14152517080381013961+a3455b04/model.neff\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "2025-11-08 22:29:21.000006:  3342  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_14152517080381013961+a3455b04/model.neff\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_13(â€¦): 100%|â–ˆ| 21.4M/21.4M [00:00<00:00, 3\n",
      "2025-11-08 22:29:24.000192:  3341  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_13340102934497073113+a3455b04/model.neff\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_14(â€¦): 100%|â–ˆ| 21.4M/21.4M [00:00<00:00, 3\n",
      "2025-11-08 22:29:24.000351:  3342  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_14770574952780443587+a3455b04/model.neff\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_63(â€¦): 100%|â–ˆ| 21.4M/21.4M [00:00<00:00, 4\n",
      "2025-11-08 22:29:30.000603:  3341  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_6394509931854585423+a3455b04/model.neff\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_44(â€¦): 100%|â–ˆ| 21.3M/21.3M [00:00<00:00, 4\n",
      "2025-11-08 22:29:30.000618:  3342  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_4493465029485591167+a3455b04/model.neff\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_17(â€¦): 100%|â–ˆ| 15.6M/15.6M [00:00<00:00, 3\n",
      "2025-11-08 22:29:40.000360:  3341  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_17239445601988651504+a3455b04/model.neff\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_53(â€¦): 100%|â–ˆ| 16.4M/16.4M [00:00<00:00, 3\n",
      "2025-11-08 22:29:40.000367:  3342  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_5391683354399705816+a3455b04/model.neff\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_31(â€¦): 100%|â–ˆ| 1.51M/1.51M [00:00<00:00, 3\n",
      "2025-11-08 22:29:47.000507:  3341  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_3188978248012181906+a3455b04/model.neff\n",
      "2025-11-08 22:29:47.000524:  3342  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_3188978248012181906+a3455b04/model.neff\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_91(â€¦): 100%|â–ˆ| 1.98M/1.98M [00:00<00:00, 4\n",
      "2025-11-08 22:29:51.000398:  3342  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_9123409164792130896+a3455b04/model.neff\n",
      "2025-11-08 22:29:51.000432:  3341  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_9123409164792130896+a3455b04/model.neff\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_96(â€¦): 100%|â–ˆ| 1.98M/1.98M [00:00<00:00, 4\n",
      "2025-11-08 22:30:02.000345:  3341  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_9654582282420716943+a3455b04/model.neff\n",
      "2025-11-08 22:30:02.000353:  3342  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_9654582282420716943+a3455b04/model.neff\n",
      "{'loss': 3.7811, 'learning_rate': 4.9500000000000004e-05, 'grad_norm': 1.4140625, 'epoch': 0.02531645569620253}\n",
      "{'loss': 3.3107, 'learning_rate': 4.9e-05, 'grad_norm': 0.6328125, 'epoch': 0.05063291139240506}\n",
      "{'loss': 3.1324, 'learning_rate': 4.85e-05, 'grad_norm': 0.62890625, 'epoch': 0.0759493670886076}\n",
      "{'loss': 3.0699, 'learning_rate': 4.8e-05, 'grad_norm': 0.66015625, 'epoch': 0.10126582278481013}\n",
      "{'loss': 3.0246, 'learning_rate': 4.75e-05, 'grad_norm': 0.609375, 'epoch': 0.12658227848101267}\n",
      "{'loss': 3.043, 'learning_rate': 4.7e-05, 'grad_norm': 0.65234375, 'epoch': 0.1518987341772152}\n",
      "{'loss': 3.0545, 'learning_rate': 4.6500000000000005e-05, 'grad_norm': 0.67578125, 'epoch': 0.17721518987341772}\n",
      "{'loss': 2.9666, 'learning_rate': 4.600000000000001e-05, 'grad_norm': 0.66015625, 'epoch': 0.20253164556962025}\n",
      "{'loss': 2.8992, 'learning_rate': 4.55e-05, 'grad_norm': 0.67578125, 'epoch': 0.22784810126582278}\n",
      "{'loss': 2.925, 'learning_rate': 4.5e-05, 'grad_norm': 0.7109375, 'epoch': 0.25316455696202533}\n",
      "{'loss': 2.9103, 'learning_rate': 4.4500000000000004e-05, 'grad_norm': 0.71484375, 'epoch': 0.27848101265822783}\n",
      "{'loss': 2.8931, 'learning_rate': 4.4000000000000006e-05, 'grad_norm': 0.76171875, 'epoch': 0.3037974683544304}\n",
      "{'loss': 2.9251, 'learning_rate': 4.35e-05, 'grad_norm': 0.81640625, 'epoch': 0.3291139240506329}\n",
      "{'loss': 2.9487, 'learning_rate': 4.3e-05, 'grad_norm': 0.859375, 'epoch': 0.35443037974683544}\n",
      "{'loss': 2.8011, 'learning_rate': 4.25e-05, 'grad_norm': 0.83203125, 'epoch': 0.379746835443038}\n",
      "{'loss': 2.8859, 'learning_rate': 4.2e-05, 'grad_norm': 0.796875, 'epoch': 0.4050632911392405}\n",
      "{'loss': 2.832, 'learning_rate': 4.15e-05, 'grad_norm': 0.84375, 'epoch': 0.43037974683544306}\n",
      "{'loss': 2.8211, 'learning_rate': 4.1e-05, 'grad_norm': 0.875, 'epoch': 0.45569620253164556}\n",
      "{'loss': 2.9584, 'learning_rate': 4.05e-05, 'grad_norm': 0.83203125, 'epoch': 0.4810126582278481}\n",
      "{'loss': 2.8849, 'learning_rate': 4e-05, 'grad_norm': 1.0234375, 'epoch': 0.5063291139240507}\n",
      "{'loss': 2.899, 'learning_rate': 3.9500000000000005e-05, 'grad_norm': 0.91796875, 'epoch': 0.5316455696202531}\n",
      "{'loss': 2.864, 'learning_rate': 3.9000000000000006e-05, 'grad_norm': 1.0078125, 'epoch': 0.5569620253164557}\n",
      "{'loss': 2.8182, 'learning_rate': 3.85e-05, 'grad_norm': 0.90234375, 'epoch': 0.5822784810126582}\n",
      "{'loss': 2.8413, 'learning_rate': 3.8e-05, 'grad_norm': 0.89453125, 'epoch': 0.6075949367088608}\n",
      "{'loss': 2.8347, 'learning_rate': 3.7500000000000003e-05, 'grad_norm': 1.0234375, 'epoch': 0.6329113924050633}\n",
      "{'loss': 2.8307, 'learning_rate': 3.7e-05, 'grad_norm': 0.99609375, 'epoch': 0.6582278481012658}\n",
      "{'loss': 2.8158, 'learning_rate': 3.65e-05, 'grad_norm': 1.015625, 'epoch': 0.6835443037974683}\n",
      "{'loss': 2.756, 'learning_rate': 3.6e-05, 'grad_norm': 1.015625, 'epoch': 0.7088607594936709}\n",
      "{'loss': 2.7585, 'learning_rate': 3.55e-05, 'grad_norm': 1.046875, 'epoch': 0.7341772151898734}\n",
      "{'loss': 2.8493, 'learning_rate': 3.5e-05, 'grad_norm': 1.0859375, 'epoch': 0.759493670886076}\n",
      "{'loss': 2.8565, 'learning_rate': 3.45e-05, 'grad_norm': 1.1640625, 'epoch': 0.7848101265822784}\n",
      "{'loss': 2.8295, 'learning_rate': 3.4000000000000007e-05, 'grad_norm': 1.109375, 'epoch': 0.810126582278481}\n",
      "{'loss': 2.7996, 'learning_rate': 3.35e-05, 'grad_norm': 1.03125, 'epoch': 0.8354430379746836}\n",
      "{'loss': 2.8014, 'learning_rate': 3.3e-05, 'grad_norm': 1.1171875, 'epoch': 0.8607594936708861}\n",
      "{'loss': 2.7726, 'learning_rate': 3.2500000000000004e-05, 'grad_norm': 1.0546875, 'epoch': 0.8860759493670886}\n",
      "{'loss': 2.7945, 'learning_rate': 3.2000000000000005e-05, 'grad_norm': 1.0625, 'epoch': 0.9113924050632911}\n",
      "{'loss': 2.8025, 'learning_rate': 3.15e-05, 'grad_norm': 1.09375, 'epoch': 0.9367088607594937}\n",
      "{'loss': 2.8167, 'learning_rate': 3.1e-05, 'grad_norm': 1.21875, 'epoch': 0.9620253164556962}\n",
      "{'loss': 2.8256, 'learning_rate': 3.05e-05, 'grad_norm': 1.09375, 'epoch': 0.9873417721518988}\n",
      "{'loss': 2.7902, 'learning_rate': 3e-05, 'grad_norm': 1.1953125, 'epoch': 1.0126582278481013}\n",
      "{'loss': 2.753, 'learning_rate': 2.95e-05, 'grad_norm': 1.046875, 'epoch': 1.0379746835443038}\n",
      "{'loss': 2.7649, 'learning_rate': 2.9e-05, 'grad_norm': 1.1875, 'epoch': 1.0632911392405062}\n",
      "{'loss': 2.7706, 'learning_rate': 2.8499999999999998e-05, 'grad_norm': 1.1484375, 'epoch': 1.0886075949367089}\n",
      "{'loss': 2.729, 'learning_rate': 2.8000000000000003e-05, 'grad_norm': 1.1328125, 'epoch': 1.1139240506329113}\n",
      "{'loss': 2.773, 'learning_rate': 2.7500000000000004e-05, 'grad_norm': 1.1015625, 'epoch': 1.139240506329114}\n",
      "{'loss': 2.8299, 'learning_rate': 2.7000000000000002e-05, 'grad_norm': 1.15625, 'epoch': 1.1645569620253164}\n",
      "{'loss': 2.7478, 'learning_rate': 2.6500000000000004e-05, 'grad_norm': 1.1171875, 'epoch': 1.189873417721519}\n",
      "{'loss': 2.7537, 'learning_rate': 2.6000000000000002e-05, 'grad_norm': 1.2421875, 'epoch': 1.2151898734177216}\n",
      "{'loss': 2.7286, 'learning_rate': 2.5500000000000003e-05, 'grad_norm': 1.3046875, 'epoch': 1.240506329113924}\n",
      "{'loss': 2.7057, 'learning_rate': 2.5e-05, 'grad_norm': 1.2265625, 'epoch': 1.2658227848101267}\n",
      "Saving model checkpoint to /home/ubuntu/environment/ml/qwen/checkpoint-500\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "[2025-11-08 22:38:29.585: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint adapter_shards began\n",
      "[2025-11-08 22:38:29.747: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint adapter_shards completed\n",
      "[2025-11-08 22:38:29.748: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 2.6985, 'learning_rate': 2.45e-05, 'grad_norm': 1.296875, 'epoch': 1.2911392405063291}\n",
      "{'loss': 2.753, 'learning_rate': 2.4e-05, 'grad_norm': 1.2890625, 'epoch': 1.3164556962025316}\n",
      "{'loss': 2.7603, 'learning_rate': 2.35e-05, 'grad_norm': 1.2734375, 'epoch': 1.3417721518987342}\n",
      "{'loss': 2.7549, 'learning_rate': 2.3000000000000003e-05, 'grad_norm': 1.3125, 'epoch': 1.3670886075949367}\n",
      "{'loss': 2.6415, 'learning_rate': 2.25e-05, 'grad_norm': 1.265625, 'epoch': 1.3924050632911391}\n",
      "{'loss': 2.7038, 'learning_rate': 2.2000000000000003e-05, 'grad_norm': 1.1953125, 'epoch': 1.4177215189873418}\n",
      "{'loss': 2.6802, 'learning_rate': 2.15e-05, 'grad_norm': 1.328125, 'epoch': 1.4430379746835442}\n",
      "{'loss': 2.8142, 'learning_rate': 2.1e-05, 'grad_norm': 1.421875, 'epoch': 1.4683544303797469}\n",
      "{'loss': 2.7389, 'learning_rate': 2.05e-05, 'grad_norm': 1.34375, 'epoch': 1.4936708860759493}\n",
      "{'loss': 2.721, 'learning_rate': 2e-05, 'grad_norm': 1.3203125, 'epoch': 1.518987341772152}\n",
      "{'loss': 2.753, 'learning_rate': 1.9500000000000003e-05, 'grad_norm': 1.3359375, 'epoch': 1.5443037974683544}\n",
      "{'loss': 2.6929, 'learning_rate': 1.9e-05, 'grad_norm': 1.3984375, 'epoch': 1.5696202531645569}\n",
      "{'loss': 2.7746, 'learning_rate': 1.85e-05, 'grad_norm': 1.2890625, 'epoch': 1.5949367088607596}\n",
      "{'loss': 2.686, 'learning_rate': 1.8e-05, 'grad_norm': 1.359375, 'epoch': 1.620253164556962}\n",
      "{'loss': 2.7106, 'learning_rate': 1.75e-05, 'grad_norm': 1.40625, 'epoch': 1.6455696202531644}\n",
      "{'loss': 2.692, 'learning_rate': 1.7000000000000003e-05, 'grad_norm': 1.421875, 'epoch': 1.6708860759493671}\n",
      "{'loss': 2.6694, 'learning_rate': 1.65e-05, 'grad_norm': 1.28125, 'epoch': 1.6962025316455698}\n",
      "{'loss': 2.6619, 'learning_rate': 1.6000000000000003e-05, 'grad_norm': 1.390625, 'epoch': 1.721518987341772}\n",
      "{'loss': 2.6968, 'learning_rate': 1.55e-05, 'grad_norm': 1.453125, 'epoch': 1.7468354430379747}\n",
      "{'loss': 2.732, 'learning_rate': 1.5e-05, 'grad_norm': 1.3359375, 'epoch': 1.7721518987341773}\n",
      "{'loss': 2.7407, 'learning_rate': 1.45e-05, 'grad_norm': 1.578125, 'epoch': 1.7974683544303798}\n",
      "{'loss': 2.7334, 'learning_rate': 1.4000000000000001e-05, 'grad_norm': 1.3671875, 'epoch': 1.8227848101265822}\n",
      "{'loss': 2.6969, 'learning_rate': 1.3500000000000001e-05, 'grad_norm': 1.34375, 'epoch': 1.8481012658227849}\n",
      "{'loss': 2.7416, 'learning_rate': 1.3000000000000001e-05, 'grad_norm': 1.4765625, 'epoch': 1.8734177215189873}\n",
      "{'loss': 2.6406, 'learning_rate': 1.25e-05, 'grad_norm': 1.40625, 'epoch': 1.8987341772151898}\n",
      "{'loss': 2.7577, 'learning_rate': 1.2e-05, 'grad_norm': 1.3828125, 'epoch': 1.9240506329113924}\n",
      "{'loss': 2.6915, 'learning_rate': 1.1500000000000002e-05, 'grad_norm': 1.359375, 'epoch': 1.9493670886075949}\n",
      "{'loss': 2.7367, 'learning_rate': 1.1000000000000001e-05, 'grad_norm': 1.4765625, 'epoch': 1.9746835443037973}\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "{'loss': 2.7231, 'learning_rate': 1.05e-05, 'grad_norm': 1.4453125, 'epoch': 2.0}\n",
      "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "{'loss': 2.6841, 'learning_rate': 1e-05, 'grad_norm': 1.3515625, 'epoch': 2.0253164556962027}\n",
      "{'loss': 2.6944, 'learning_rate': 9.5e-06, 'grad_norm': 1.359375, 'epoch': 2.050632911392405}\n",
      "{'loss': 2.6765, 'learning_rate': 9e-06, 'grad_norm': 1.3515625, 'epoch': 2.0759493670886076}\n",
      "{'loss': 2.6767, 'learning_rate': 8.500000000000002e-06, 'grad_norm': 1.515625, 'epoch': 2.1012658227848102}\n",
      "{'loss': 2.6811, 'learning_rate': 8.000000000000001e-06, 'grad_norm': 1.390625, 'epoch': 2.1265822784810124}\n",
      "{'loss': 2.7372, 'learning_rate': 7.5e-06, 'grad_norm': 1.421875, 'epoch': 2.151898734177215}\n",
      "{'loss': 2.7412, 'learning_rate': 7.000000000000001e-06, 'grad_norm': 1.3984375, 'epoch': 2.1772151898734178}\n",
      "{'loss': 2.676, 'learning_rate': 6.5000000000000004e-06, 'grad_norm': 1.484375, 'epoch': 2.2025316455696204}\n",
      "{'loss': 2.629, 'learning_rate': 6e-06, 'grad_norm': 1.484375, 'epoch': 2.2278481012658227}\n",
      "{'loss': 2.6564, 'learning_rate': 5.500000000000001e-06, 'grad_norm': 1.328125, 'epoch': 2.2531645569620253}\n",
      "{'loss': 2.6631, 'learning_rate': 5e-06, 'grad_norm': 1.3984375, 'epoch': 2.278481012658228}\n",
      "{'loss': 2.6626, 'learning_rate': 4.5e-06, 'grad_norm': 1.484375, 'epoch': 2.3037974683544302}\n",
      "{'loss': 2.6848, 'learning_rate': 4.000000000000001e-06, 'grad_norm': 1.5546875, 'epoch': 2.329113924050633}\n",
      "{'loss': 2.7247, 'learning_rate': 3.5000000000000004e-06, 'grad_norm': 1.4609375, 'epoch': 2.3544303797468356}\n",
      "{'loss': 2.5768, 'learning_rate': 3e-06, 'grad_norm': 1.703125, 'epoch': 2.379746835443038}\n",
      "{'loss': 2.6756, 'learning_rate': 2.5e-06, 'grad_norm': 1.4140625, 'epoch': 2.4050632911392404}\n",
      "{'loss': 2.6317, 'learning_rate': 2.0000000000000003e-06, 'grad_norm': 1.4375, 'epoch': 2.430379746835443}\n",
      "{'loss': 2.6153, 'learning_rate': 1.5e-06, 'grad_norm': 1.4453125, 'epoch': 2.4556962025316453}\n",
      "{'loss': 2.7588, 'learning_rate': 1.0000000000000002e-06, 'grad_norm': 1.5390625, 'epoch': 2.481012658227848}\n",
      "{'loss': 2.685, 'learning_rate': 5.000000000000001e-07, 'grad_norm': 1.4921875, 'epoch': 2.5063291139240507}\n",
      "{'loss': 2.7012, 'learning_rate': 0.0, 'grad_norm': 1.4375, 'epoch': 2.5316455696202533}\n",
      "Saving model checkpoint to /home/ubuntu/environment/ml/qwen/checkpoint-1000\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "[2025-11-08 22:47:06.042: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint adapter_shards began\n",
      "[2025-11-08 22:47:06.208: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint adapter_shards completed\n",
      "[2025-11-08 22:47:06.209: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 1065.8655, 'train_samples_per_second': 1.876, 'train_steps_per_second': 0.938, 'train_loss': 2.790102918624878, 'epoch': 2.5316455696202533}\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "Consolidating LoRA adapter shards\n",
      "Merging LoRA adapter shards into base model\n",
      "Saving merged model to /home/ubuntu/environment/ml/qwen/merged_model\n",
      "Saving tokenizer to /home/ubuntu/environment/ml/qwen/merged_model\n",
      "Merged model config:\n",
      "Qwen3Model(\n",
      "  (embed_tokens): Embedding(151936, 2048)\n",
      "  (layers): ModuleList(\n",
      "    (0-27): 28 x Qwen3DecoderLayer(\n",
      "      (self_attn): Qwen3Attention(\n",
      "        (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "        (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "        (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "      )\n",
      "      (mlp): Qwen3MLP(\n",
      "        (gate_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "        (up_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "        (down_proj): Linear(in_features=6144, out_features=2048, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "      (input_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
      "      (post_attention_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
      "    )\n",
      "  )\n",
      "  (norm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
      "  (rotary_emb): Qwen3RotaryEmbedding()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "!torchrun \\\n",
    "  --nnodes 1 \\\n",
    "  --nproc_per_node 2 \\\n",
    "  finetune_model.py \\\n",
    "  --model_id Qwen/Qwen3-1.7B \\\n",
    "  --tokenizer_id Qwen/Qwen3-1.7B \\\n",
    "  --output_dir ~/environment/ml/qwen \\\n",
    "  --bf16 True \\\n",
    "  --gradient_checkpointing True \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --learning_rate 5e-5 \\\n",
    "  --max_steps 1000 \\\n",
    "  --per_device_train_batch_size 2 \\\n",
    "  --tensor_parallel_size 2 \\\n",
    "  --lora_r 16 \\\n",
    "  --lora_alpha 32 \\\n",
    "  --lora_dropout 0.05 \\\n",
    "  --dataloader_drop_last True \\\n",
    "  --disable_tqdm True \\\n",
    "  --logging_steps 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation\n",
    "\n",
    "After completing the fine-tuning process, the next step is to compile the trained model for AWS Trainium inference using the Hugging Face Optimum Neuron toolchain.\n",
    "Neuron compilation optimizes the model graph and converts it into a Neuron Executable File Format (NEFF), enabling efficient execution on NeuronCores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/commands/env.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/commands/env.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/kvcache/kv_cache_manager.py:24: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..attention.gqa import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:45: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "INFO:Neuron:Generating HLOs for the following models: ['context_encoding_model', 'token_generation_model']\n",
      "[2025-11-08 22:49:11.085: I neuronx_distributed/parallel_layers/parallel_state.py:628] > initializing tensor model parallel with size 2\n",
      "[2025-11-08 22:49:11.085: I neuronx_distributed/parallel_layers/parallel_state.py:629] > initializing pipeline model parallel with size 1\n",
      "[2025-11-08 22:49:11.085: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing context model parallel with size 1\n",
      "[2025-11-08 22:49:11.085: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing data parallel with size 1\n",
      "[2025-11-08 22:49:11.085: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing world size to 2\n",
      "[2025-11-08 22:49:11.086: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x72cf5e7749d0>, 'Ascending Ring PG Group')>\n",
      "[2025-11-08 22:49:11.086: I neuronx_distributed/parallel_layers/parallel_state.py:668] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1]]\n",
      "[2025-11-08 22:49:11.087: I neuronx_distributed/parallel_layers/parallel_state.py:669] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1]]\n",
      "[2025-11-08 22:49:11.087: I neuronx_distributed/parallel_layers/parallel_state.py:670] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1]]\n",
      "[2025-11-08 22:49:11.087: I neuronx_distributed/parallel_layers/parallel_state.py:671] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1]]\n",
      "[2025-11-08 22:49:11.087: I neuronx_distributed/parallel_layers/parallel_state.py:672] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1]]\n",
      "[2025-11-08 22:49:11.087: I neuronx_distributed/parallel_layers/parallel_state.py:673] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1]]\n",
      "INFO:Neuron:Generating 1 hlos for key: context_encoding_model\n",
      "INFO:Neuron:Started loading module context_encoding_model\n",
      "INFO:Neuron:Finished loading module context_encoding_model in 0.13972806930541992 seconds\n",
      "INFO:Neuron:generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:299: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs_soft_max, dim=dim, on_cpu=self.on_cpu)\n",
      "Add predicate {{0,+,-1}<i0=[0:128:1]>,+,0}<i1=[0:2048:1]>\n",
      "start lb and ub of  {0,+,-1}<i0=[0:128:1]> is 0 0\n",
      "Add predicate {{255,+,0}<i0=[0:128:1]>,+,-1}<i1=[0:2048:1]>\n",
      "start lb and ub of  {{255,+,0}<i0=[0:128:1]>,+,-1}<i1=[0:2048:1]> is 255 255\n",
      "before build_invert_ranges alive full {\n",
      "  0 <= i1=[0:2048:1] <= 2047; alive full {\n",
      "    0 <= i1=[0:2048:1] <= 2047; 1 <= i0=[0:128:1] <= 127; alive leaf\n",
      "  }\n",
      "  256 <= i1=[0:2048:1] <= 2047; alive {\n",
      "    256 <= i1=[0:2048:1] <= 2047; 0 <= i0=[0:128:1] <= 127; alive full leaf\n",
      "  }\n",
      "}\n",
      "generated domains alive full {\n",
      "  0 <= i1=[0:2048:1] <= 255; alive {\n",
      "    0 <= i1=[0:2048:1] <= 255; 0 <= i0=[0:128:1] <= 0; alive leaf\n",
      "  }\n",
      "}\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:262: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=1, shape=torch.Size([1, 512]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "INFO:Neuron:Finished generating HLO for context_encoding_model in 2.6311888694763184 seconds, input example shape = torch.Size([1, 512])\n",
      "INFO:Neuron:Generating 1 hlos for key: token_generation_model\n",
      "INFO:Neuron:Started loading module token_generation_model\n",
      "INFO:Neuron:Finished loading module token_generation_model in 0.09883761405944824 seconds\n",
      "INFO:Neuron:generating HLO: token_generation_model, input example shape = torch.Size([1, 1])\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:299: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs_soft_max, dim=dim, on_cpu=self.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:262: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "INFO:Neuron:Finished generating HLO for token_generation_model in 2.336385726928711 seconds, input example shape = torch.Size([1, 1])\n",
      "INFO:Neuron:Generated all HLOs in 5.274081230163574 seconds\n",
      "INFO:Neuron:Starting compilation for the priority HLO\n",
      "INFO:Neuron:'token_generation_model' is the priority model with bucket rank 0\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/libneuronxla/neuron_cc_wrapper.py:283: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.\n",
      "  warnings.warn(SyntaxWarning(\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_de(â€¦): 100%|â–ˆ| 2.14M/2.14M [00:00<00:00, 4\n",
      "Fetched cached neuronxcc-2.20.9961.0+0acef03a/MODULE_de733c6f96020a1e5f56+a9d440f5/model.neff from aws-neuron/optimum-neuron-cache\n",
      "2025-11-08 22:49:17.000426:  7565  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_de733c6f96020a1e5f56+a9d440f5/model.neff\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_de(â€¦): 100%|â–ˆ| 2.27M/2.27M [00:00<00:00, 4\n",
      "Fetched cached neuronxcc-2.20.9961.0+0acef03a/MODULE_de733c6f96020a1e5f56+a9d440f5/wrapped_neff.hlo from aws-neuron/optimum-neuron-cache\n",
      "INFO:Neuron:Done compilation for the priority HLO in 1.943960189819336 seconds\n",
      "INFO:Neuron:Updating the hlo module with optimized layout\n",
      "INFO:Neuron:Done optimizing weight layout for all HLOs in 0.5386555194854736 seconds\n",
      "INFO:Neuron:Starting compilation for all HLOs\n",
      "INFO:Neuron:Neuron compiler flags: --auto-cast=none --model-type=transformer --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' -O2  --lnc=1 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk0/log-neuron-cc.txt\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/libneuronxla/neuron_cc_wrapper.py:245: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.\n",
      "  warnings.warn(SyntaxWarning(\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_05(â€¦): 100%|â–ˆ| 3.06M/3.06M [00:00<00:00, 7\n",
      "Fetched cached neuronxcc-2.20.9961.0+0acef03a/MODULE_057bc784fc164fb34d3e+ed72d204/model.neff from aws-neuron/optimum-neuron-cache\n",
      "2025-11-08 22:49:19.000856:  7565  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_057bc784fc164fb34d3e+ed72d204/model.neff\n",
      "INFO:Neuron:Finished Compilation for all HLOs in 1.0045971870422363 seconds\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_e3(â€¦): 100%|â–ˆ| 1.28M/1.28M [00:00<00:00, 3\n",
      "Fetched cached neuronxcc-2.20.9961.0+0acef03a/MODULE_e3031c3c114f7c905db7+ae6a382b/model.neff from aws-neuron/optimum-neuron-cache\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_e3031c3c114f7c905db7+ae6a382b/wrapped_neff.hlo not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "INFO:Neuron:Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_e3031c3c114f7c905db7+ae6a382b/model.neff\n",
      "INFO:Neuron:Done preparing weight layout transformation\n",
      "INFO:Neuron:Finished building model in 9.823018074035645 seconds\n",
      "Configuration saved in /home/ubuntu/environment/ml/qwen/compiled_model/neuron_config.json\n",
      "INFO:Neuron:Sharding Weights for ranks: 0...1\n",
      "[2025-11-08 22:49:21.034: I neuronx_distributed/parallel_layers/parallel_state.py:628] > initializing tensor model parallel with size 2\n",
      "[2025-11-08 22:49:21.034: I neuronx_distributed/parallel_layers/parallel_state.py:629] > initializing pipeline model parallel with size 1\n",
      "[2025-11-08 22:49:21.034: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing context model parallel with size 1\n",
      "[2025-11-08 22:49:21.034: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing data parallel with size 1\n",
      "[2025-11-08 22:49:21.034: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing world size to 2\n",
      "[2025-11-08 22:49:21.213: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x72cf5e7749d0>, 'Ascending Ring PG Group')>\n",
      "[2025-11-08 22:49:21.213: I neuronx_distributed/parallel_layers/parallel_state.py:668] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1]]\n",
      "[2025-11-08 22:49:21.213: I neuronx_distributed/parallel_layers/parallel_state.py:669] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1]]\n",
      "[2025-11-08 22:49:21.213: I neuronx_distributed/parallel_layers/parallel_state.py:670] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1]]\n",
      "[2025-11-08 22:49:21.213: I neuronx_distributed/parallel_layers/parallel_state.py:671] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1]]\n",
      "[2025-11-08 22:49:21.213: I neuronx_distributed/parallel_layers/parallel_state.py:672] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1]]\n",
      "[2025-11-08 22:49:21.213: I neuronx_distributed/parallel_layers/parallel_state.py:673] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1]]\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/trace/trace.py:640: UserWarning: Removing redundant keys from checkpoint: []\n",
      "  warnings.warn(f\"Removing redundant keys from checkpoint: {keys_to_delete}\")\n",
      "INFO:Neuron:Done Sharding weights in 9.464608975999909\n"
     ]
    }
   ],
   "source": [
    "!optimum-cli export neuron \\\n",
    "  --model /home/ubuntu/environment/ml/qwen/merged_model \\\n",
    "  --task text-generation \\\n",
    "  --sequence_length 512 \\\n",
    "  --batch_size 1 \\\n",
    "  /home/ubuntu/environment/ml/qwen/compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "We will install the Optimum Neuron vllm library.  Then, run inference using the compiled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: optimum-neuron[vllm] in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: transformers~=4.51.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (4.51.3)\n",
      "Requirement already satisfied: accelerate==1.8.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.8.1)\n",
      "Requirement already satisfied: optimum~=1.24.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.24.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.29.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (0.33.4)\n",
      "Requirement already satisfied: numpy<=1.25.2,>=1.22.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.25.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (3.20.3)\n",
      "Collecting vllm==0.9.2 (from optimum-neuron[vllm])\n",
      "  Downloading vllm-0.9.2-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (25.0)\n",
      "Requirement already satisfied: psutil in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (2.7.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (0.5.3)\n",
      "Requirement already satisfied: regex in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2025.7.34)\n",
      "Collecting cachetools (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: sentencepiece in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (4.67.1)\n",
      "Collecting blake3 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading blake3-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting py-cpuinfo (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.21.4)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.116.1)\n",
      "Requirement already satisfied: aiohttp in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.12.15)\n",
      "Collecting openai<=1.90.0,>=1.52.0 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading openai-1.90.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pydantic>=2.10 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2.11.7)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.22.1)\n",
      "Requirement already satisfied: pillow in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (11.3.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading lm_format_enforcer-0.10.12-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting llguidance<0.8.0,>=0.7.11 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting outlines==0.1.11 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: lark==1.2.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.2.2)\n",
      "Collecting xgrammar==0.1.19 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading xgrammar-0.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (4.14.1)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.18.0)\n",
      "Collecting partial-json-parser (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (27.0.0)\n",
      "Collecting msgspec (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf>=0.13.0 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting mistral_common>=1.6.2 (from mistral_common[opencv]>=1.6.2->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting einops (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting compressed-tensors==0.10.2 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading compressed_tensors-0.10.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting depyf==0.18.0 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: cloudpickle in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.1.1)\n",
      "Collecting watchfiles (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading watchfiles-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-json-logger in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.3.0)\n",
      "Requirement already satisfied: scipy in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.12.0)\n",
      "Collecting ninja (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting pybase64 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading pybase64-1.4.2-cp310-cp310-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: numba==0.61.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.61.2)\n",
      "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading ray-2.51.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting torch>=2.0.0 (from accelerate==1.8.1->optimum-neuron[vllm])\n",
      "  Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchaudio==2.7.0 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading torchaudio-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchvision==0.22.0 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Using cached torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting xformers==0.0.30 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting astor (from depyf==0.18.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: dill in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from depyf==0.18.0->vllm==0.9.2->optimum-neuron[vllm]) (0.3.8)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from numba==0.61.2->vllm==0.9.2->optimum-neuron[vllm]) (0.44.0)\n",
      "Collecting interegular (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (1.6.0)\n",
      "Collecting diskcache (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: referencing in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (4.25.0)\n",
      "Collecting pycountry (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting airportsdata (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading airportsdata-20250909-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2.8.8)\n",
      "Requirement already satisfied: fsspec in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.11.1.6)\n",
      "Collecting triton==3.3.0 (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm])\n",
      "  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (80.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading jiter-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.10->vllm==0.9.2->optimum-neuron[vllm]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.10->vllm==0.9.2->optimum-neuron[vllm]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.10->vllm==0.9.2->optimum-neuron[vllm]) (0.4.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface-hub>=0.29.0->optimum-neuron[vllm]) (1.1.5)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.47.2)\n",
      "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading fastapi_cli-0.0.14-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting typer>=0.15.1 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading fastapi_cloud_cli-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading rignore-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting sentry-sdk>=2.20.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading sentry_sdk-2.43.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jinja2->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (3.0.2)\n",
      "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.6.2->mistral_common[opencv]>=1.6.2->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (0.26.0)\n",
      "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: click!=8.3.0,>=7.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (8.2.1)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading msgpack-1.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting cupy-cuda12x (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading cupy_cuda12x-13.6.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.9.2->optimum-neuron[vllm]) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.9.2->optimum-neuron[vllm]) (2.5.0)\n",
      "Requirement already satisfied: rich>=13.7.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (14.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.3.0)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading httptools-0.7.1-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading uvloop-0.22.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (1.20.1)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm])\n",
      "  Downloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading vllm-0.9.2-cp38-abi3-manylinux1_x86_64.whl (383.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m383.4/383.4 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading compressed_tensors-0.10.2-py3-none-any.whl (169 kB)\n",
      "Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m168.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m175.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m144.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl (31.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m156.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m171.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m142.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lm_format_enforcer-0.10.12-py3-none-any.whl (44 kB)\n",
      "Downloading openai-1.90.0-py3-none-any.whl (734 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m734.6/734.6 kB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (359 kB)\n",
      "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading fastapi_cli-0.0.14-py3-none-any.whl (11 kB)\n",
      "Downloading fastapi_cloud_cli-0.3.1-py3-none-any.whl (19 kB)\n",
      "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m283.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m175.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m293.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ray-2.51.1-cp310-cp310-manylinux2014_x86_64.whl (71.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.2/71.2 MB\u001b[0m \u001b[31m137.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (406 kB)\n",
      "Downloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\n",
      "Downloading rignore-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (959 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m959.8/959.8 kB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.43.0-py2.py3-none-any.whl (400 kB)\n",
      "Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading httptools-0.7.1-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (440 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading uvloop-0.22.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m158.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (455 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Downloading airportsdata-20250909-py3-none-any.whl (914 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m914.4/914.4 kB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading blake3-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (387 kB)\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Downloading cupy_cuda12x-13.6.0-cp310-cp310-manylinux2014_x86_64.whl (112.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.2/112.2 MB\u001b[0m \u001b[31m166.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pybase64-1.4.2-cp310-cp310-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (68 kB)\n",
      "Installing collected packages: py-cpuinfo, fastrlock, websockets, uvloop, uvicorn, triton, shellingham, sentry-sdk, rignore, python-multipart, python-dotenv, pycountry, pybase64, partial-json-parser, opencv-python-headless, ninja, msgspec, msgpack, llguidance, jiter, interegular, httptools, gguf, einops, dnspython, distro, diskcache, cupy-cuda12x, cachetools, blake3, astor, airportsdata, tiktoken, email-validator, depyf, watchfiles, typer, torch, rich-toolkit, pydantic-extra-types, lm-format-enforcer, xformers, torchvision, torchaudio, ray, prometheus-fastapi-instrumentator, outlines_core, openai, xgrammar, outlines, mistral_common, fastapi-cloud-cli, fastapi-cli, compressed-tensors, vllm\n",
      "\u001b[2K  Attempting uninstall: tritonâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/55\u001b[0m [uvicorn]\n",
      "\u001b[2K    Found existing installation: triton 3.3.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/55\u001b[0m [uvicorn]\n",
      "\u001b[2K    Uninstalling triton-3.3.1:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/55\u001b[0m [uvicorn]\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/55\u001b[0m [uvicorn]\n",
      "\u001b[2K  Attempting uninstall: torchâ”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34/55\u001b[0m [depyf]uda12x]-headless]\n",
      "\u001b[2K    Found existing installation: torch 2.7.190mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34/55\u001b[0m [depyf]\n",
      "\u001b[2K    Uninstalling torch-2.7.1:â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37/55\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.1mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37/55\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvisionâ”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41/55\u001b[0m [xformers]-enforcer]s]\n",
      "\u001b[2K    Found existing installation: torchvision 0.22.1mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41/55\u001b[0m [xformers]\n",
      "\u001b[2K    Uninstalling torchvision-0.22.1:â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42/55\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.22.1[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42/55\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55/55\u001b[0m [vllm]0m [vllm]0m [compressed-tensors]umentator]\n",
      "\u001b[1A\u001b[2KSuccessfully installed airportsdata-20250909 astor-0.8.1 blake3-1.0.8 cachetools-6.2.1 compressed-tensors-0.10.2 cupy-cuda12x-13.6.0 depyf-0.18.0 diskcache-5.6.3 distro-1.9.0 dnspython-2.8.0 einops-0.8.1 email-validator-2.3.0 fastapi-cli-0.0.14 fastapi-cloud-cli-0.3.1 fastrlock-0.8.3 gguf-0.17.1 httptools-0.7.1 interegular-0.3.3 jiter-0.11.1 llguidance-0.7.30 lm-format-enforcer-0.10.12 mistral_common-1.8.5 msgpack-1.1.2 msgspec-0.19.0 ninja-1.13.0 openai-1.90.0 opencv-python-headless-4.11.0.86 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 py-cpuinfo-9.0.0 pybase64-1.4.2 pycountry-24.6.1 pydantic-extra-types-2.10.6 python-dotenv-1.2.1 python-multipart-0.0.20 ray-2.51.1 rich-toolkit-0.15.1 rignore-0.7.6 sentry-sdk-2.43.0 shellingham-1.5.4 tiktoken-0.12.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 triton-3.3.0 typer-0.20.0 uvicorn-0.38.0 uvloop-0.22.1 vllm-0.9.2 watchfiles-1.1.1 websockets-15.0.1 xformers-0.0.30 xgrammar-0.1.19\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optimum-neuron[vllm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-08 23:00:06 [config.py:841] This model supports multiple tasks: {'reward', 'generate', 'embed', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 11-08 23:00:06 [config.py:1472] Using max model len 2048\n",
      "INFO 11-08 23:00:06 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.2) with config: model='/home/ubuntu/environment/ml/qwen/compiled_model', speculative_config=None, tokenizer='/home/ubuntu/environment/ml/qwen/compiled_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cpu, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/home/ubuntu/environment/ml/qwen/compiled_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":1,\"local_cache_dir\":null}, use_cached_outputs=False, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Loading sharded checkpoint from /home/ubuntu/environment/ml/qwen/compiled_model/checkpoint/weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 11-08 23:00:07 [config.py:4861] Current vLLM config is not set.\n",
      "INFO 11-08 23:00:07 [executor_base.py:113] # neuron blocks: 2, # CPU blocks: 0\n",
      "INFO 11-08 23:00:07 [executor_base.py:118] Maximum concurrency for 2048 tokens per request: 2.00x\n",
      "INFO 11-08 23:00:07 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ec32c760de446b86186a4b2175ab06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd952e793cd4657badbf39186642a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################################\n",
      "Prompt: '\\n<|im_start|>system\\nYou are medical diagnoser. \\nThe patient will talk to you about their medical condition or illnesses of symptoms they might have.\\nYou have to advise them appropriately. \\nMention any relevant diseases, health checks and medicines that the patient should look into.<|im_end|>\\n<|im_start|>user\\nI got 104 fever, what medicine do i take? <|im_end|>\\n<|im_start|>assistant\\n', \n",
      "\n",
      " Generated text: '<think>\\n\\n</think>\\n\\nhello I understand your concern take fever and pain relief medicine acetaminophen paracetamol twice daily and also take antipyretic tablet along with it for 10 days consult a doctor and get her examined and investigated further for the etiology of fever and also get the blood sugar level tested and also get your urine examined and urine culture and sensitivity sensitive antibacterial medicines may be started after blood examination and urine culture and sensitivity test if there is any urinary tract infection to give effective treatment to the patient' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(\n",
    "    model=\"/home/ubuntu/environment/ml/qwen/compiled_model\", #local compiled model\n",
    "    max_num_seqs=1,\n",
    "    max_model_len=2048,\n",
    "    device=\"neuron\",\n",
    "    tensor_parallel_size=2,\n",
    "    override_neuron_config={})\n",
    "example1=\"\"\"\n",
    "<|im_start|>system\n",
    "You are medical diagnoser. \n",
    "The patient will talk to you about their medical condition or illnesses of symptoms they might have.\n",
    "You have to advise them appropriately. \n",
    "Mention any relevant diseases, health checks and medicines that the patient should look into.<|im_end|>\n",
    "<|im_start|>user\n",
    "I got 104 fever, what medicine do i take? <|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "prompts = [\n",
    "    example1\n",
    "]\n",
    "\n",
    "sampling_params = SamplingParams(max_tokens=2048, temperature=0.8)\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "print(\"#########################################################\")\n",
    "\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, \\n\\n Generated text: {generated_text!r} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cd /home/ubuntu/environment/ml/qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consolidate_adapter_shards_and_merge_model.py  finetune_model_copy_2.py\n",
      "finetune_model.py\t\t\t       requirements.txt\n",
      "finetune_model_copy.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuronx_venv_pytorch_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
